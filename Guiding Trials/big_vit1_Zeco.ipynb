{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZd7WMWuGDrG"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dpznGLViLEfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece52679-55a8-4191-d5fb-b26feb48dbb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-0JoAWJGpK9",
        "outputId": "b741f6bd-c4bf-4ac8-c429-19cc69edcb08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Graduation_Project/CheXpert-v1.0-small.zip > /dev/null"
      ],
      "metadata": {
        "id": "FqwzHe1eNC4J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pB0huaQJGDrH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications import imagenet_utils\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from myowngen_v2 import DataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "import pandas as pd\n",
        "import cv2\n",
        "#tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kbVxYzMGDrL"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qYCLhL0nGDrM"
      },
      "outputs": [],
      "source": [
        "# Values are from table 4.\n",
        "patch_size = 4 # 2x2, for the Transformer blocks.\n",
        "image_size = 256\n",
        "expansion_factor = 2  # expansion factor for the MobileNetV2 blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3kSJY2ORGDrQ"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
        "    conv_layer = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, activation=tf.nn.swish, padding=\"same\"\n",
        "    )\n",
        "    return conv_layer(x)\n",
        "\n",
        "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
        "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    if strides == 2:\n",
        "        m = layers.ZeroPadding2D(padding=imagenet_utils.correct_pad(m, 3))(m)\n",
        "    m = layers.DepthwiseConv2D(\n",
        "        3, strides=strides, padding=\"same\" if strides == 1 else \"valid\", use_bias=False\n",
        "    )(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "\n",
        "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
        "        return layers.Add()([m, x])\n",
        "    return m\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.swish)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, x])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
        "        # Skip connection 2.\n",
        "        x = layers.Add()([x3, x2])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
        "    # Local projection with convolutions.\n",
        "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
        "    local_features = conv_block(\n",
        "        local_features, filters=projection_dim, kernel_size=1, strides=strides\n",
        "    )\n",
        "\n",
        "    # Unfold into patches and then pass through Transformers.\n",
        "    num_patches = int((local_features.shape[1] * local_features.shape[2]) / patch_size)\n",
        "    non_overlapping_patches = layers.Reshape((patch_size, num_patches, projection_dim))(\n",
        "        local_features\n",
        "    )\n",
        "    global_features = transformer_block(\n",
        "        non_overlapping_patches, num_blocks, projection_dim\n",
        "    )\n",
        "\n",
        "    # Fold into conv-like feature-maps.\n",
        "    folded_feature_map = layers.Reshape((*local_features.shape[1:-1], projection_dim))(\n",
        "        global_features\n",
        "    )\n",
        "\n",
        "    # Apply point-wise conv -> concatenate with the input features.\n",
        "    folded_feature_map = conv_block(\n",
        "        folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides\n",
        "    )\n",
        "    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map])\n",
        "\n",
        "    # Fuse the local and global features using a convoluion layer.\n",
        "    local_global_features = conv_block(\n",
        "        local_global_features, filters=projection_dim, strides=strides\n",
        "    )\n",
        "\n",
        "    return local_global_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZCZaup47GDrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51f575f-ca1a-419a-8e7f-20b6dadc8269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 256, 256, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 8)  224         ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 16  128         ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 128, 16  64         ['conv2d_1[0][0]']               \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.silu (TFOpLambda)        (None, 128, 128, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 128, 128, 16  144        ['tf.nn.silu[0][0]']             \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 16  64         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.silu_1 (TFOpLambda)      (None, 128, 128, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 8)  128         ['tf.nn.silu_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 8)  32         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 8)  0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 16)   1168        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 32)   512         ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.silu_2 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 64, 64, 32)  288         ['tf.nn.silu_2[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 32)  128         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.silu_3 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 16)   512         ['tf.nn.silu_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 16)  64          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 64, 16)   0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 32)   512         ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.silu_4 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 65, 65, 32)  0           ['tf.nn.silu_4[0][0]']           \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 32)  288         ['zero_padding2d[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 32)  128         ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.silu_5 (TFOpLambda)      (None, 32, 32, 32)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 24)   768         ['tf.nn.silu_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 48)   1152        ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 48)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.silu_6 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 32, 32, 48)  432         ['tf.nn.silu_6[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 48)  192         ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_7 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 24)   1152        ['tf.nn.silu_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 24)  96          ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 48)   1152        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 48)  192         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_8 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 32, 32, 48)  432         ['tf.nn.silu_8[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 48)  192         ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_9 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 24)   1152        ['tf.nn.silu_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 24)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 48)   1152        ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 48)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_10 (TFOpLambda)     (None, 32, 32, 48)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 33, 33, 48)  0           ['tf.nn.silu_10[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 48)  432         ['zero_padding2d_1[0][0]']       \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 48)  192         ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_11 (TFOpLambda)     (None, 16, 16, 48)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   2304        ['tf.nn.silu_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 48)  192         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   27712       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   4160        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 4, 64, 64)    0           ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 4, 64, 64)   128         ['reshape[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 4, 64, 64)   33216       ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 64, 64)    0           ['multi_head_attention[0][0]',   \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 4, 64, 64)   128         ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4, 64, 128)   8320        ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4, 64, 128)   0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4, 64, 64)    8256        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 4, 64, 64)    0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 4, 64, 64)    0           ['dropout_1[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 4, 64, 64)   128         ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 4, 64, 64)   33216       ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 64, 64)    0           ['multi_head_attention_1[0][0]', \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 4, 64, 64)   128         ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4, 64, 128)   8320        ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 4, 64, 128)   0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4, 64, 64)    8256        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 4, 64, 64)    0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 64, 64)    0           ['dropout_3[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 16, 16, 64)   0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 48)   3120        ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 64)   55360       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 128)  8192        ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 128)  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_12 (TFOpLambda)     (None, 16, 16, 128)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " zero_padding2d_2 (ZeroPadding2  (None, 17, 17, 128)  0          ['tf.nn.silu_12[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 8, 8, 128)   1152        ['zero_padding2d_2[0][0]']       \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 8, 8, 128)   512         ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_13 (TFOpLambda)     (None, 8, 8, 128)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 64)     8192        ['tf.nn.silu_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 8, 8, 80)     46160       ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 8, 8, 80)     6480        ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 4, 16, 80)    0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 4, 16, 80)   160         ['reshape_2[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 4, 16, 80)    0           ['multi_head_attention_2[0][0]', \n",
            "                                                                  'reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 4, 16, 80)   160         ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 4, 16, 160)   0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4, 16, 80)    12880       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 4, 16, 80)    0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 4, 16, 80)    0           ['dropout_5[0][0]',              \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 4, 16, 80)   160         ['add_9[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 4, 16, 80)    0           ['multi_head_attention_3[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 4, 16, 80)   160         ['add_10[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 4, 16, 160)   0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 4, 16, 80)    12880       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 4, 16, 80)    0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 4, 16, 80)    0           ['dropout_7[0][0]',              \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 4, 16, 80)   160         ['add_11[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_8[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 4, 16, 80)    0           ['multi_head_attention_4[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 4, 16, 80)   160         ['add_12[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 4, 16, 160)   12960       ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 4, 16, 160)   0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 4, 16, 80)    12880       ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 4, 16, 80)    0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 4, 16, 80)    0           ['dropout_9[0][0]',              \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 4, 16, 80)   160         ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 4, 16, 80)   51760       ['layer_normalization_10[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 4, 16, 80)    0           ['multi_head_attention_5[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 4, 16, 80)   160         ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4, 16, 160)   12960       ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 4, 16, 160)   0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4, 16, 80)    12880       ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 4, 16, 80)    0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 4, 16, 80)    0           ['dropout_11[0][0]',             \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 8, 8, 80)     0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 8, 8, 64)     5184        ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 128)    0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 8, 8, 80)     92240       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 8, 8, 160)    12800       ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 8, 8, 160)   640         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_14 (TFOpLambda)     (None, 8, 8, 160)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " zero_padding2d_3 (ZeroPadding2  (None, 9, 9, 160)   0           ['tf.nn.silu_14[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 4, 4, 160)   1440        ['zero_padding2d_3[0][0]']       \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 160)   640         ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_15 (TFOpLambda)     (None, 4, 4, 160)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 4, 4, 80)     12800       ['tf.nn.silu_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 80)    320         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 4, 4, 160)    12800       ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4, 4, 160)   640         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_16 (TFOpLambda)     (None, 4, 4, 160)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadding2  (None, 5, 5, 160)   0           ['tf.nn.silu_16[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 2, 2, 160)   1440        ['zero_padding2d_4[0][0]']       \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 2, 2, 160)   640         ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_17 (TFOpLambda)     (None, 2, 2, 160)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 2, 2, 80)     12800       ['tf.nn.silu_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 2, 2, 80)    320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 2, 2, 128)    92288       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 2, 2, 128)    16512       ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 4, 1, 128)    0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 4, 1, 128)   256         ['reshape_4[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (MultiH  (None, 4, 1, 128)   131968      ['layer_normalization_12[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 4, 1, 128)    0           ['multi_head_attention_6[0][0]', \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 4, 1, 128)   256         ['add_16[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 4, 1, 256)    33024       ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 4, 1, 256)    0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 4, 1, 128)    32896       ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 4, 1, 128)    0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 4, 1, 128)    0           ['dropout_13[0][0]',             \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 4, 1, 128)   256         ['add_17[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (MultiH  (None, 4, 1, 128)   131968      ['layer_normalization_14[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 4, 1, 128)    0           ['multi_head_attention_7[0][0]', \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 4, 1, 128)   256         ['add_18[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 4, 1, 256)    33024       ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 4, 1, 256)    0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 4, 1, 128)    32896       ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 4, 1, 128)    0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 4, 1, 128)    0           ['dropout_15[0][0]',             \n",
            "                                                                  'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 4, 1, 128)   256         ['add_19[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (MultiH  (None, 4, 1, 128)   131968      ['layer_normalization_16[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 4, 1, 128)    0           ['multi_head_attention_8[0][0]', \n",
            "                                                                  'add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 4, 1, 128)   256         ['add_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 4, 1, 256)    33024       ['layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 4, 1, 256)    0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 4, 1, 128)    32896       ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 4, 1, 128)    0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 4, 1, 128)    0           ['dropout_17[0][0]',             \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 2, 2, 128)    0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 2, 2, 80)     10320       ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 2, 2, 160)    0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 2, 2, 128)    184448      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 2, 2, 192)    24768       ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 2, 2, 192)    331968      ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 2, 2, 192)    37056       ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 4, 1, 192)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 4, 1, 192)   384         ['reshape_6[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (MultiH  (None, 4, 1, 192)   296256      ['layer_normalization_18[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 4, 1, 192)    0           ['multi_head_attention_9[0][0]', \n",
            "                                                                  'reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_19 (LayerN  (None, 4, 1, 192)   384         ['add_22[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 4, 1, 384)    74112       ['layer_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 4, 1, 384)    0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 4, 1, 192)    73920       ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 4, 1, 192)    0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 4, 1, 192)    0           ['dropout_19[0][0]',             \n",
            "                                                                  'add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_20 (LayerN  (None, 4, 1, 192)   384         ['add_23[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (Multi  (None, 4, 1, 192)   296256      ['layer_normalization_20[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 4, 1, 192)    0           ['multi_head_attention_10[0][0]',\n",
            "                                                                  'add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_21 (LayerN  (None, 4, 1, 192)   384         ['add_24[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 4, 1, 384)    74112       ['layer_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 4, 1, 384)    0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 4, 1, 192)    73920       ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 4, 1, 192)    0           ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 4, 1, 192)    0           ['dropout_21[0][0]',             \n",
            "                                                                  'add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_22 (LayerN  (None, 4, 1, 192)   384         ['add_25[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (Multi  (None, 4, 1, 192)   296256      ['layer_normalization_22[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 4, 1, 192)    0           ['multi_head_attention_11[0][0]',\n",
            "                                                                  'add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_23 (LayerN  (None, 4, 1, 192)   384         ['add_26[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 4, 1, 384)    74112       ['layer_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 4, 1, 384)    0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 4, 1, 192)    73920       ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 4, 1, 192)    0           ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 4, 1, 192)    0           ['dropout_23[0][0]',             \n",
            "                                                                  'add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 2, 2, 192)    0           ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 2, 2, 192)    37056       ['reshape_7[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 2, 2, 384)    0           ['conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 2, 2, 192)    663744      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 2, 2, 320)    61760       ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 320)         0           ['conv2d_37[0][0]']              \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 14)           4494        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,139,470\n",
            "Trainable params: 4,136,046\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_mobilevit(num_classes=14):\n",
        "    inputs = keras.Input((256, 256, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "    # \n",
        "    x = conv_block(x, filters=8)\n",
        "    x = inverted_residual_block(\n",
        "    x, expanded_channels=8 * expansion_factor, output_channels=8\n",
        "    )\n",
        "    # Initial conv-stem -> MV2 block.\n",
        "    x = conv_block(x, filters=16)\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=16 * expansion_factor, output_channels=16\n",
        "    )\n",
        "\n",
        "    #Downsampling with MV2 block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=16 * expansion_factor, output_channels=24, strides=2\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
        "    )\n",
        "\n",
        "    # First MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=48, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n",
        "\n",
        "    # Second MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=64 * expansion_factor, output_channels=64, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n",
        "    # \n",
        "\n",
        "    # Third MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "    x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=3, projection_dim=128)\n",
        "    x = conv_block(x, filters=192, kernel_size=1, strides=1)\n",
        "    #\n",
        "    x = mobilevit_block(x, num_blocks=3, projection_dim=192)\n",
        "    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n",
        "\n",
        "    # Classification head.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "mobilevit_xxs = create_mobilevit()\n",
        "mobilevit_xxs.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzmW6Qe7GDrY"
      },
      "source": [
        "## Dataset preparation\n",
        "\n",
        "We will be using the\n",
        "[`tf_flowers`](https://www.tensorflow.org/datasets/catalog/tf_flowers)\n",
        "dataset to demonstrate the model. Unlike other Transformer-based architectures,\n",
        "MobileViT uses a simple augmentation pipeline primarily because it has the properties\n",
        "of a CNN."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path  =  'sample_4.csv'\n",
        "valid_path   = \"val_sample_2.csv\"\n",
        "data_path    = '/content/'\n",
        "weights_path = '/content/drive/MyDrive/Graduation_Project/Big_Vit.hdf5'"
      ],
      "metadata": {
        "id": "5mUE_ypPNNXn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(sample_path)\n",
        "#train.drop(columns=['Binary'], inplace=True)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "u33NJOnkNeqN",
        "outputId": "52f234bb-74f8-4969-f902-f82b767d8bf6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6da98032-0739-44e2-bf8b-004b22809671\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00057/study2/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>48</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00060/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>44</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>PA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00060/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>44</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00066/study1/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>61</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>PA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00066/study1/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>61</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da98032-0739-44e2-bf8b-004b22809671')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6da98032-0739-44e2-bf8b-004b22809671 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6da98032-0739-44e2-bf8b-004b22809671');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                Path  ... Support Devices\n",
              "0  CheXpert-v1.0-small/train/patient00057/study2/...  ...             NaN\n",
              "1  CheXpert-v1.0-small/train/patient00060/study1/...  ...             NaN\n",
              "2  CheXpert-v1.0-small/train/patient00060/study1/...  ...             NaN\n",
              "3  CheXpert-v1.0-small/train/patient00066/study1/...  ...             NaN\n",
              "4  CheXpert-v1.0-small/train/patient00066/study1/...  ...             NaN\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.loc[:, train.columns[5:]] = train.loc[:, train.columns[5:]].fillna(0)\n",
        "\n",
        "to_take = list(set(train.columns[5:])-set(['Edema', 'Atelectasis']))\n",
        "train.loc[:, to_take] = train.loc[:, to_take].replace({-1:0})\n",
        "\n",
        "train.loc[:, ['Edema', 'Atelectasis']] = train.loc[:, ['Edema', 'Atelectasis']].replace({-1:1})"
      ],
      "metadata": {
        "id": "aGurdCJ4NnsE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.read_csv(valid_path)\n",
        "valid.drop('Sex_y', axis=1, inplace=True)\n",
        "valid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0ThuOKfa3Kpv",
        "outputId": "2fef4af9-5a0f-45cc-af63-a6395b5dbc5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-534a6326-67ad-4dbc-8be2-4d9648a89c4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient04947/study3/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>56</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>PA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient38193/study3/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>67</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient47458/study7/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>57</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient38830/study3/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>56</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient26417/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>50</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-534a6326-67ad-4dbc-8be2-4d9648a89c4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-534a6326-67ad-4dbc-8be2-4d9648a89c4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-534a6326-67ad-4dbc-8be2-4d9648a89c4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                Path  ... Support Devices\n",
              "0  CheXpert-v1.0-small/train/patient04947/study3/...  ...               0\n",
              "1  CheXpert-v1.0-small/train/patient38193/study3/...  ...               1\n",
              "2  CheXpert-v1.0-small/train/patient47458/study7/...  ...               1\n",
              "3  CheXpert-v1.0-small/train/patient38830/study3/...  ...               1\n",
              "4  CheXpert-v1.0-small/train/patient26417/study1/...  ...               1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataGenerator(data_path, train, 14, batch_size=32, shape=(256,256, 3), shuffle=True)\n",
        "val_dataset = DataGenerator(data_path, valid, 14, batch_size=32, shape=(256,256, 3), shuffle=True)"
      ],
      "metadata": {
        "id": "Harlw8w-N_jZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DK8Od4yGDra"
      },
      "source": [
        "The authors use a multi-scale data sampler to help the model learn representations of\n",
        "varied scales. In this example, we discard this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXk5ev_oGDrb"
      },
      "source": [
        "## Load and prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70gWmaqBGDrc"
      },
      "source": [
        "## Train a MobileViT (XXS) model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YesCnn35GDrc"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "label_smoothing_factor = 0.1\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "#auto = tf.data.AUTOTUNE\n",
        "#resize_bigger = 280\n",
        "num_classes =14\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "#loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing_factor)\n",
        "\n",
        "\n",
        "def run_experiment(epochs=epochs):\n",
        "    mobilevit_xxs = create_mobilevit(num_classes=num_classes)\n",
        "    mobilevit_xxs.load_weights(weights_path)\n",
        "\n",
        "    # mobilevit_xxs.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"binary_accuracy\", tf.keras.metrics.AUC(multi_label=True) ])\n",
        "\n",
        "    # checkpoint = ModelCheckpoint(weights_path, monitor='val_auc', verbose=1, save_best_only=False, mode='auto', save_freq = 'epoch')\n",
        "    # early = EarlyStopping(monitor=\"val_auc\", mode='auto', patience=5, restore_best_weights=False)\n",
        "    # callbacks_list = [checkpoint, early]\n",
        "\n",
        "    # mobilevit_xxs.fit(train_dataset, validation_data=val_dataset, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=callbacks_list)\n",
        "    # #mobilevit_xxs.load_weights(weights_path)\n",
        "    # _, accuracy = mobilevit_xxs.evaluate(val_dataset)\n",
        "    # print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return mobilevit_xxs\n",
        "\n",
        "\n",
        "mobilevit_xxs = run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9BNnLugJ4mbM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR7jYCkwGDrd"
      },
      "source": [
        "## Results and TFLite conversion\n",
        "\n",
        "With about one million parameters, getting to ~85% top-1 accuracy on 256x256 resolution is\n",
        "a strong result. This MobileViT mobile is fully compatible with TensorFlow Lite (TFLite)\n",
        "and can be converted with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def custom_auc(y_true, y_pred):\n",
        "    labels = ['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion']\n",
        "\n",
        "    results = pd.DataFrame(index=labels)\n",
        "\n",
        "\n",
        "    scores = []\n",
        "    for i in [2, 5, 6, 8, 10]:\n",
        "        score = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
        "        scores.append(score)\n",
        "        \n",
        "    results['AUC'] = scores\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "tI_EqtX5k3d1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_path   = '/content/CheXpert-v1.0-small/valid.csv'\n",
        "val = pd.read_csv(val_path)"
      ],
      "metadata": {
        "id": "VaFfNF3mDmuU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_generator = DataGenerator(data_path, train, 14, batch_size=1, shape=(224,224, 3), shuffle=False)\n",
        "val_generator = DataGenerator(data_path, val, 14, batch_size=1, shape=(256,256, 3), shuffle=False)"
      ],
      "metadata": {
        "id": "LvyZvDKWDq1G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual\n",
        "y_val_true   = val.iloc[:, 5:].values\n",
        "\n",
        "# predicted\n",
        "y_val_pred   = mobilevit_xxs.predict(val_generator)\n",
        "\n",
        "results = custom_auc(y_val_true, y_val_pred)\n",
        "results.AUC.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I0VoplYDulV",
        "outputId": "8c7725c8-20d2-46d0-f9ee-2629325710bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8272416355207272"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgJDRCdoGDre"
      },
      "outputs": [],
      "source": [
        "# # Serialize the model as a SavedModel.\n",
        "# mobilevit_xxs.save(\"mobilevit_xxs\")\n",
        "\n",
        "# # Convert to TFLite. This form of quantization is called\n",
        "# # post-training dynamic-range quantization in TFLite.\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(\"mobilevit_xxs\")\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.target_spec.supported_ops = [\n",
        "#     tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
        "#     tf.lite.OpsSet.SELECT_TF_OPS,  # Enable TensorFlow ops.\n",
        "# ]\n",
        "# tflite_model = converter.convert()\n",
        "# open(\"mobilevit_xxs.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6SxisrKGDre"
      },
      "source": [
        "To learn more about different quantization recipes available in TFLite and running\n",
        "inference with TFLite models, check out\n",
        "[this official resource](https://www.tensorflow.org/lite/performance/post_training_quantization)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "big_vit1_Zeco.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}