{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-xhXJXPeLrea"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/Graduation_Project/CheXpert-v1.0-small.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bP4dbGLrDIGk"
   },
   "outputs": [],
   "source": [
    "from torch import nn, sqrt\n",
    "import torch\n",
    "import sys\n",
    "from math import sqrt\n",
    "from MBConv import MBConvBlock\n",
    "from SelfAttention import ScaledDotProductAttention\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nWgdNwRdDA6m"
   },
   "outputs": [],
   "source": [
    "class CoAtNet(nn.Module):\n",
    "    def __init__(self, in_ch, image_size, out_chs=[64,96,192,384,768]):\n",
    "        super().__init__()\n",
    "        self.out_chs = out_chs\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.maxpool1d = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.s0 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_ch,in_ch,kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.mlp0 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_chs[0], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_chs[0], out_chs[0], kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        self.s1 = MBConvBlock(ksize=3, input_filters=out_chs[0], output_filters=out_chs[0], image_size=image_size//2)\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv2d(out_chs[0], out_chs[1], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_chs[1], out_chs[1], kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.s2 = MBConvBlock(ksize=3, input_filters=out_chs[1], output_filters=out_chs[1], image_size=image_size//4)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv2d(out_chs[1],out_chs[2],kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_chs[2],out_chs[2],kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.s3 = ScaledDotProductAttention(out_chs[2],out_chs[2]//8,out_chs[2]//8,8)\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(out_chs[2],out_chs[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_chs[3],out_chs[3])\n",
    "        )\n",
    "\n",
    "        self.s4 = ScaledDotProductAttention(out_chs[3], out_chs[3]//8, out_chs[3]//8, 8)\n",
    "        self.mlp4 = nn.Sequential(\n",
    "            nn.Linear(out_chs[3],out_chs[4]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_chs[4],out_chs[4])\n",
    "        )\n",
    "\n",
    "        self.mlp5 = nn.Sequential(\n",
    "            nn.Conv2d(out_chs[4],out_chs[4],kernel_size=5),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        #print(x.shape)\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        #stage0\n",
    "        y = self.mlp0(self.s0(x))\n",
    "        y = self.maxpool2d(y)\n",
    "\n",
    "        #stage1\n",
    "        y = self.mlp1(self.s1(y))\n",
    "        y = self.maxpool2d(y)\n",
    "\n",
    "        #stage2\n",
    "        y = self.mlp2(self.s2(y))\n",
    "        y = self.maxpool2d(y)\n",
    "\n",
    "        #stage3\n",
    "        y = y.reshape(B,self.out_chs[2],-1).permute(0,2,1) #B,N,C\n",
    "        y = self.mlp3(self.s3(y,y,y))\n",
    "        y = self.maxpool1d(y.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "        #stage4\n",
    "        y = self.mlp4(self.s4(y,y,y))\n",
    "        y = self.maxpool1d(y.permute(0,2,1))\n",
    "\n",
    "        #stage5\n",
    "        #y = self.mlp5(y.unsqueeze(1))\n",
    "        #y = self.AvgPool2d(18)(y)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #y = torch.nn.Softmax(dim=0)(y)\n",
    "        #print(y.shape)\n",
    "        # N = y.shape[-1]\n",
    "        # y = y.reshape(B,self.out_chs[4],int(sqrt(N)),int(sqrt(N)))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ls2Y7XCaGpZa"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class croppedDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self, main_dir, meta_data, image_size):\n",
    "        'Initialization'\n",
    "        self.meta_data = meta_data\n",
    "        self.main_dir = main_dir\n",
    "        # self.image_size = image_size\n",
    "        self.transform = T.Compose([T.ToPILImage(),\n",
    "                                    T.CenterCrop(0.75 * 64),\n",
    "                                    T.Resize(image_size),\n",
    "                                    T.RandomHorizontalFlip(),\n",
    "                                    T.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.meta_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        image = cv2.imread(os.path.join(self.main_dir, self.meta_data.iloc[index, 0]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        x = self.transform(image).squeeze(0)\n",
    "        #x = torch.from_numpy(image).permute((2, 0, 1)).unsqueeze(0).float()\n",
    "        y = torch.from_numpy(self.meta_data.iloc[index, 5:].astype(np.float32).values)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cC2M-9wLLax5"
   },
   "outputs": [],
   "source": [
    "pure_train = pd.read_csv('pure_train.csv')\n",
    "pure_val = pd.read_csv('pure_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9B-BlNlYLl1d"
   },
   "outputs": [],
   "source": [
    "# def show_images(images, nmax=64):\n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     ax.set_xticks([]); ax.set_yticks([])\n",
    "#     ax.imshow(make_grid((images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "# def show_batch(dl, nmax=64):\n",
    "#     for images in dl:\n",
    "#         show_images(images, nmax)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g92YxzmqLQKQ"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_path  = \"/content\"\n",
    "image_size = 256\n",
    "\n",
    "cropped_dataset = croppedDataset(main_dir=data_path, meta_data=pure_train, image_size=image_size)\n",
    "train_dl = DataLoader(cropped_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RgZRoJydNAkN"
   },
   "outputs": [],
   "source": [
    "#x = torch.randn(1,3,224,224)\n",
    "coatnet = CoAtNet(3, 256)\n",
    "# y = coatnet(train_dl)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzehknATofHm",
    "outputId": "b7b7e0fb-2286-4dc7-973e-b230bbd01bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [10, 3, 256, 256]              84\n",
      "              ReLU-2          [10, 3, 256, 256]               0\n",
      "            Conv2d-3          [10, 3, 256, 256]              84\n",
      "            Conv2d-4         [10, 64, 256, 256]             256\n",
      "              ReLU-5         [10, 64, 256, 256]               0\n",
      "            Conv2d-6         [10, 64, 256, 256]           4,160\n",
      "         MaxPool2d-7         [10, 64, 128, 128]               0\n",
      "         ZeroPad2d-8         [10, 64, 130, 130]               0\n",
      "Conv2dStaticSamePadding-9         [10, 64, 128, 128]             576\n",
      "      BatchNorm2d-10         [10, 64, 128, 128]             128\n",
      "MemoryEfficientSwish-11         [10, 64, 128, 128]               0\n",
      "         Identity-12             [10, 64, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [10, 16, 1, 1]           1,040\n",
      "MemoryEfficientSwish-14             [10, 16, 1, 1]               0\n",
      "         Identity-15             [10, 16, 1, 1]               0\n",
      "Conv2dStaticSamePadding-16             [10, 64, 1, 1]           1,088\n",
      "         Identity-17         [10, 64, 128, 128]               0\n",
      "Conv2dStaticSamePadding-18         [10, 64, 128, 128]           4,096\n",
      "      BatchNorm2d-19         [10, 64, 128, 128]             128\n",
      "      MBConvBlock-20         [10, 64, 128, 128]               0\n",
      "           Conv2d-21         [10, 96, 128, 128]           6,240\n",
      "             ReLU-22         [10, 96, 128, 128]               0\n",
      "           Conv2d-23         [10, 96, 128, 128]           9,312\n",
      "        MaxPool2d-24           [10, 96, 64, 64]               0\n",
      "        ZeroPad2d-25           [10, 96, 66, 66]               0\n",
      "Conv2dStaticSamePadding-26           [10, 96, 64, 64]             864\n",
      "      BatchNorm2d-27           [10, 96, 64, 64]             192\n",
      "MemoryEfficientSwish-28           [10, 96, 64, 64]               0\n",
      "         Identity-29             [10, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-30             [10, 24, 1, 1]           2,328\n",
      "MemoryEfficientSwish-31             [10, 24, 1, 1]               0\n",
      "         Identity-32             [10, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-33             [10, 96, 1, 1]           2,400\n",
      "         Identity-34           [10, 96, 64, 64]               0\n",
      "Conv2dStaticSamePadding-35           [10, 96, 64, 64]           9,216\n",
      "      BatchNorm2d-36           [10, 96, 64, 64]             192\n",
      "      MBConvBlock-37           [10, 96, 64, 64]               0\n",
      "           Conv2d-38          [10, 192, 64, 64]          18,624\n",
      "             ReLU-39          [10, 192, 64, 64]               0\n",
      "           Conv2d-40          [10, 192, 64, 64]          37,056\n",
      "        MaxPool2d-41          [10, 192, 32, 32]               0\n",
      "           Linear-42            [10, 1024, 192]          37,056\n",
      "           Linear-43            [10, 1024, 192]          37,056\n",
      "           Linear-44            [10, 1024, 192]          37,056\n",
      "          Dropout-45        [10, 8, 1024, 1024]               0\n",
      "           Linear-46            [10, 1024, 192]          37,056\n",
      "ScaledDotProductAttention-47            [10, 1024, 192]               0\n",
      "           Linear-48            [10, 1024, 384]          74,112\n",
      "             ReLU-49            [10, 1024, 384]               0\n",
      "           Linear-50            [10, 1024, 384]         147,840\n",
      "        MaxPool1d-51             [10, 384, 512]               0\n",
      "           Linear-52             [10, 512, 384]         147,840\n",
      "           Linear-53             [10, 512, 384]         147,840\n",
      "           Linear-54             [10, 512, 384]         147,840\n",
      "          Dropout-55          [10, 8, 512, 512]               0\n",
      "           Linear-56             [10, 512, 384]         147,840\n",
      "ScaledDotProductAttention-57             [10, 512, 384]               0\n",
      "           Linear-58             [10, 512, 768]         295,680\n",
      "             ReLU-59             [10, 512, 768]               0\n",
      "           Linear-60             [10, 512, 768]         590,592\n",
      "        MaxPool1d-61             [10, 768, 256]               0\n",
      "================================================================\n",
      "Total params: 1,945,872\n",
      "Trainable params: 1,945,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.50\n",
      "Forward/backward pass size (MB): 3714.46\n",
      "Params size (MB): 7.42\n",
      "Estimated Total Size (MB): 3729.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(coatnet, (3, 256, 256), batch_size=10, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ISxhPINZdZei"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(coatnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzueGcVONJ4a"
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = coatnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9KUjm2vYZ4Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CoAtNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
